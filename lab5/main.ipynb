{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b67ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import csv\n",
    "import cv2\n",
    "from typing import Any, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff98488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path_to_annot_file: str, transform: Any=None, train: bool=False, test: bool=False, valid: bool=False) -> None:\n",
    "        self.path_to_annot_file = path_to_annot_file\n",
    "        self.data = self.get_data(path_to_annot_file, train, test, valid)\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_data(self, path_to_annot_file: str, train: bool=False, test: bool=False, valid: bool=False) -> pd.DataFrame:\n",
    "        data = pd.read_csv(path_to_annot_file, usecols = (0, 2), names = ('path_to_image', 'label'))\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "        data['label'] = data['label'].apply(lambda label: 0 if label == 'cat' else 1)\n",
    "        train_size = int(0.8 * data.shape[0])\n",
    "        test_valid_size = int(0.1 * data.shape[0])\n",
    "        if train == True:\n",
    "            data = data.iloc[:train_size, :]\n",
    "        elif test == True:\n",
    "            data = data.iloc[train_size:train_size + test_valid_size, :]\n",
    "        elif valid == True:\n",
    "            data = data.iloc[train_size + test_valid_size:, :]\n",
    "        return data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.tensor, int]:\n",
    "        path_to_image = self.data.iloc[index, 0]\n",
    "        image = cv2.cvtColor(cv2.imread(path_to_image), cv2.COLOR_BGR2RGB)\n",
    "        label = self.data.iloc[index, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a7195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                    torchvision.transforms.Resize((224, 224)),\n",
    "                                                    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861622df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(path_to_annot_file='annotation.csv', transform=transforms, train = True)\n",
    "test_data = MyDataset(path_to_annot_file='annotation.csv', transform=transforms, test = True)\n",
    "valid_data = MyDataset(path_to_annot_file='annotation.csv', transform=transforms, valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf6779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 199, 201)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eacdf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88605520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data.data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd269f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.data['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
